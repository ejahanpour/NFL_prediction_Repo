{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import os  # there is an issue with running some machine learning application on MacOX and this is to resolve it\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# metadata\n",
    "subset_rate, test_portion = 0.3, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/train.csv', low_memory = False)\n",
    "dataset['IsRusher'] = False\n",
    "dataset.loc[dataset.NflId == dataset.NflIdRusher, 'IsRusher'] = True\n",
    "dataset['OffenseDefense'] = 'D'\n",
    "dataset['OffenseDefense'] = np.where((dataset.PossessionTeam == dataset.HomeTeamAbbr) & \\\n",
    "                                       (dataset.Team == 'home'), 'O', \n",
    "                                np.where((dataset.PossessionTeam == dataset.VisitorTeamAbbr) & \\\n",
    "                                        (dataset.Team == 'away'), 'O', 'D'))\n",
    "# with %%time using pandas is taking longer time\n",
    "# dataset['OffenseDefense'] = dataset[((dataset.PossessionTeam == dataset.HomeTeamAbbr) & (dataset.Team == 'home')) | \\\n",
    "#                                     ((dataset.PossessionTeam == dataset.VisitorTeamAbbr) & (dataset.Team == 'away'))] ='O'\n",
    "game_id = random.sample(list(dataset.GameId.unique()), int(subset_rate * len(dataset.GameId.unique())))\n",
    "test_id, train_id = game_id[:int(test_portion * len(game_id))], game_id[int(test_portion * len(game_id)):]\n",
    "train_plays = dataset.loc[dataset.GameId.isin(train_id), 'PlayId'].unique()\n",
    "test_plays = dataset.loc[dataset.GameId.isin(test_id), 'PlayId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_train_test(dataset, play_id_lists):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for play_id in play_id_lists:\n",
    "        game_data = dataset[dataset.PlayId == play_id]\n",
    "        cols_to_dl = ['PlayId', 'X', 'Y', 'S', 'A', 'Orientation', 'IsRusher', 'OffenseDefense', 'PlayDirection', 'Yards']\n",
    "        spatial_data = game_data[cols_to_dl]\n",
    "        rusher_data = spatial_data[spatial_data.IsRusher]\n",
    "        if spatial_data.PlayDirection.values[0] == 'right':\n",
    "            spatial_data.loc[:, ['X', 'Y']] = spatial_data.loc[:,['X', 'Y']].values - rusher_data[['X', 'Y']].values\n",
    "        else:\n",
    "            spatial_data.loc[:,['X', 'Y']] = rusher_data.loc[:,['X', 'Y']].values - spatial_data.loc[:,['X', 'Y']].values\n",
    "        spatial_data['RusherDistance'] = np.sqrt(np.square(spatial_data.X) + np.square(spatial_data.Y))\n",
    "        spatial_data = spatial_data.sort_values(by = ['OffenseDefense', 'RusherDistance'])\n",
    "        dl_input = list(pd.concat([spatial_data.X, spatial_data.Y, spatial_data.S, spatial_data.A, \n",
    "                                  spatial_data.Orientation, spatial_data.RusherDistance]))\n",
    "        X.append(dl_input)\n",
    "        dl_output = []\n",
    "        dl_output[:199] = [0] * 199\n",
    "        dl_output[99 + int(spatial_data.Yards.values[0])] = 1\n",
    "        Y.append(dl_output)\n",
    "    return torch.FloatTensor(X), torch.FloatTensor(Y), scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, scaler = transform_train_test(train_plays)\n",
    "x_test, y_test, _ = transform_train_test(test_plays, is_train = False, scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in, n_h, n_out, batch_size, lr, epoch_size = x_train.shape[1], 200, y_train.shape[1], 32, 0.01, 100\n",
    "model = nn.Sequential(nn.Linear(n_in, n_h),\n",
    "                      nn.Sigmoid(), \n",
    "                      nn.Linear(n_h, n_out), \n",
    "                      nn.Softmax()\n",
    "                     )\n",
    "criterion = nn.MSELoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss value: nan\n",
      "test mean squared error is nan\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_size):\n",
    "    y_pred = model(x_train)\n",
    "    \n",
    "    # get the loss function\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"epoch %s loss value: %.3f\"%(epoch, loss.item()))\n",
    "        \n",
    "    # zero the gradient\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # back propogate\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the parameter\n",
    "    optim.step()\n",
    "    \n",
    "test_pred = model(x_test)\n",
    "test_MSE = torch.mean((test_pred - y_test)**2)\n",
    "print('test mean squared error is %.3f' %(test_MSE.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.7400e+00,  5.2300e+00,  6.7200e+00,  5.0700e+00,  8.5400e+00,\n",
       "         9.5900e+00,  1.2270e+01,  1.4450e+01,  1.3440e+01,  7.9500e+00,\n",
       "         2.3560e+01,  0.0000e+00,  3.9600e+00,  1.1600e+00,  4.8200e+00,\n",
       "         5.7400e+00,  5.1000e+00,  6.2500e+00,  7.9000e+00,  7.8200e+00,\n",
       "         8.9200e+00,  6.5600e+00,  9.8000e-01,  3.0400e+00, -1.9300e+00,\n",
       "         6.9900e+00, -2.9800e+00,  1.9300e+00, -5.9900e+00,  8.6600e+00,\n",
       "        -1.5120e+01,  1.8800e+01, -1.3400e+00,  0.0000e+00, -1.9800e+00,\n",
       "         4.6100e+00,  2.1000e-01, -2.0000e+00,  3.9400e+00,  2.8400e+00,\n",
       "         1.3700e+00, -4.4400e+00, -1.5850e+01,  1.8170e+01,  3.6300e+00,\n",
       "         4.8700e+00,  2.7300e+00,  4.9200e+00,  3.4400e+00,  4.1300e+00,\n",
       "         2.1000e+00,  3.3100e+00,  1.1600e+00,  3.9000e+00,  2.4100e+00,\n",
       "         6.3200e+00,  5.6600e+00,  3.2700e+00,  4.0400e+00,  2.3300e+00,\n",
       "         5.4200e+00,  4.4400e+00,  5.0700e+00,  1.2300e+00,  4.3400e+00,\n",
       "         4.6900e+00,  2.7200e+00,  2.1600e+00,  1.6700e+00,  2.7500e+00,\n",
       "         1.7600e+00,  2.0800e+00,  3.2000e+00,  2.8700e+00,  1.8200e+00,\n",
       "         3.5200e+00,  3.2700e+00,  2.8800e+00,  3.4000e+00,  3.7800e+00,\n",
       "         1.5300e+00,  2.9700e+00,  2.3600e+00,  1.7400e+00,  1.6900e+00,\n",
       "         1.2900e+00,  8.5000e-01,  3.7500e+00,  1.5352e+02,  8.0320e+01,\n",
       "         1.3348e+02,  1.1804e+02,  1.6635e+02,  1.5363e+02,  1.8087e+02,\n",
       "         1.5411e+02,  1.9007e+02,  1.4182e+02,  1.8223e+02,  4.3100e+00,\n",
       "         7.5770e+01,  2.0397e+02,  3.3972e+02,  3.2090e+01,  9.2910e+01,\n",
       "         1.6900e+00,  2.3910e+01,  2.6975e+02,  3.5939e+02,  3.1780e+01,\n",
       "         5.8231e+00,  6.0493e+00,  6.9917e+00,  8.6351e+00,  9.0450e+00,\n",
       "         9.7823e+00,  1.3654e+01,  1.6846e+01,  2.0230e+01,  2.0412e+01,\n",
       "         2.3598e+01,  0.0000e+00,  4.4274e+00,  4.7537e+00,  4.8246e+00,\n",
       "         6.0785e+00,  6.4447e+00,  6.8650e+00,  8.0179e+00,  8.9926e+00,\n",
       "         1.8188e+01,  1.9318e+01])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
